The Stanford A100 report provides great insight of how life would be in 2030 and thoughts on how AI would apply to that. However, I hold different opinions on some parts of the report when I’m reading it.

As is stated in the A100 report, cloud-based machine learning would greatly improve the home robots. But my point of view is that privacy issue will be the single biggest barrier to cloud-based AI, as you’ll need to upload the data to cloud server in order to get things working or to train the neural network, which means people have to upload their 3D home-model to central servers for their robots to work and patients have to upload their detailed physical condition for AI to perform operations on them. There are already plenty of complains on apps that collects user data in the background and there will surely be more on cloud-based machine learning. For example, there was an app last year that uses Generative adversarial networks (GANs) to turn user’s picture into stylish painting or combine two totally different picture together with the combination of their styles and contents. That app got criticized due to privacy issues soon after it got famous. I think the best way is to get the trained model from the server and locally evaluate the results, keeping the user data local. As for training, we can locally train the neural networks and send the result back to the server so that what gets sent to the central server most of the time no longer contains sensitive data.  

Also about the autonomous driving car, it is true that it will be popular in the future, but the security issue will always be a concern. The current technology allow cars to do basic driving, like on a highway or city road, but the programs are very likely to go wrong if a car is driving itself on a unseened environment, like in the desert or on a road with lots of barriers. Another big problem is that although the auto-driving may function well on a road where most drivers are human just like nowadays, in the future however, most of cars on the road are probably driver-less. And AI drives the cars differently as we human do, so the auto-driving may not behave as well as they now do.

As for AI in education, I don’t think full-featured teaching robot which can replace traditional teachers will arrive in the near future. First of all, that requires very advanced natural language processing that allows the user to perform dialog-based conversation including the context, background and what previous thing users are referring to, which I don’t believe will come true shortly. Moreover, the teaching robots need to be able to explain things in different ways, which means generating parallel sentences and talking about the same thing in a different angel. Or in some circumstances, the robot may even need to visualize a concept to make the learner fully understand it. None of them, in my humble opinion, will come to reality in a short time. 

I’m also concerned about AI applies in healthcare. Just last year, Kaggle Inc. announced that they made huge progress in predicting lung cancer using machine learning trained by the LUNA CT dataset. That is a already large dataset, yet the accuracy is still not promising. What will most likely to happen is that we don’t have enough data to begin with, and because of the bad performance or inaccurate result, people refused to use that, causing less and less data get collected. And it’s basically a bad loop.

Although some aspects of the report are challengeable, artificial intelligence still no doubt has a bright future.
