	The healthcare sector holds much promise for AI application and the report Stanford One Hundred Year Study on Artificial Intelligence brings this into light. This report discusses some of the difficulties and barriers to AI application, as well as many other aspects of AI. It reads, “Poor human-computer interaction methods and the inherent difficulties and risks of implementing technologies in such a large and complex system have slowed realization of AI’s promise in healthcare. The reduction or removal of these obstacles, combined with innovations still on the horizon, have the potential to significantly improve health outcomes and quality of life for millions of people in the coming years.” The authors attribute the difficulties of instantiating AI in healthcare, due to existing regulations, to the risk of implementing the technologies and poor human-computer interaction, which is misleading because there is little risk in implementing AI in healthcare if done properly and the barriers of human-computer interaction methods are also minimal, due to their natural decrease in the near years.
	This article overestimates the risk involved in the application of AI in healthcare.
	The authors attribute the difficulties of instantiating AI in healthcare to the risk of implementing the technologies and poor human-computer interaction. However, these are not the root causes of why this task is so difficult. There is little risk in actually implementing the AI because of the vetting an application would have to endure to actually be used. Look at the drug industry; the Federal Drug Administration requires years of research and testing for new drugs to be released to the general patient populous. This would be the same for AI, so by the time any AI was to be used it would have significantly less risk than many other aspects of healthcare. Obviously humans make mistakes, and machines do too, but through simulation and testing an AI powered surgery robot, for example, could potentially have millions of surgeries worth of experience before doing any actual surgery, outweighing any humans experience. The AI is the more trustworthy option and therefore less risky.
	To argue that the introduction of AI to healthcare would require the reduction or removal of the current risks is also holed because AI is, according to the report and in some sense, the synthesis of intelligence. This is so vague that there is so much space for AI to be applied in healthcare that requires little risk. An example would be using an AI to diagnose non-serious illness, so doctors would have more time for more serious issues. And, even this would be a monumental step for AI, improving health outcomes.
	Another reason that AI doctors may incite unease and be perceived as risky is because machines break down and malfunction, however this is outweighed by what they can do and does not incite real concern for risk because of the expected thoroughness of maintenance on any AI. As long as the hospital or provider of the robot maintains the health of the robot or AI with regular check-ups and software updates, the risk of this is low.
	Also, poor human computer interaction methods as a barrier to AI improvements in healthcare is not a major problem that does not necessarily need to be the highest of priorities and is not a reason for its inability to be accepted; especially, when it comes to AI that interact with doctors and not patients. Younger doctors and and the young doctors of the next fifteen years will be much more open to working with AI due to the modern generations greater acceptance of technology and its benefits.


Works Cited
Peter Stone, Rodney Brooks, Erik Brynjolfsson, Ryan Calo, Oren Etzioni, Greg Hager, Julia Hirschberg, Shivaram Kalyanakrishnan, Ece Kamar, Sarit Kraus, Kevin Leyton-Brown, David Parkes, William Press, AnnaLee Saxenian, Julie Shah, Milind Tambe, and Astro Teller.  "Artificial Intelligence and Life in 2030." One Hundred Year Study on Artificial Intelligence: Report of the 2015-2016 Study Panel, Stanford University, Stanford, CA,  September 2016. Doc: http://ai100.stanford.edu/2016-report. Accessed:  September 6, 2016.
