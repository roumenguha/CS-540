Artificial Intelligence Cannot Remove Human Biases
	Ever since artificial intelligence was drawn into people¡¯s sight, artificial intelligence has been applied in many fields such as transportation and education. Some people believed that artificial intelligence had the potential to remove human bias, as machines are always regarded to be rational and fair. Similarly, according to ¡°Artificial Intelligence and Life in 2030¡±, it is feasible to apply artificial intelligence tools to lower human bias. However, artificial intelligence tools cannot restrain human bias because they learn the bias from human and they cannot counteract the bias purposely.
	The first reason that artificial intelligence cannot reduce human prejudice is that when artificial intelligence is learning from human¡¯s behaviors, it accepts the same stereotypes human hold. Human¡¯s writing or talking often conveys bias, such as the preference of pronouns when describing a job, for example, ¡°he¡± for doctors and ¡°she¡± for nurses. After processing human¡¯s written texts, artificial intelligence machines exhibit the same bias too. Google¡¯s artificial intelligence is biased as it sometimes translates neutral pronouns as ¡°he¡± or ¡°she¡± for different jobs like doctors and nurses (Hutson, 2016). Not only for jobs, associations between human and gender and fields appear from machines as well. A group of scientists analyzed the definition of the same word on different machines and found obvious correlations between women and arts and between men and science by evaluating the contexts in which the same word always appeared (Hutson, 2016). As the inputs of these machines are human written texts which may contain unobvious prejudices, and artificially intelligent machines are programmed to pick up this information and learn it in order to give satisfying feedback to human, the output that machines produce may be prejudiced, as an extension of human themselves. As a result, the artificial intelligence cannot prevent prejudicing.
	Another reason that artificial intelligence cannot diminish human partiality is that artificial intelligence is usually not supplied with features to abate partiality consciously. When processing biased information, artificial intelligence does not have a moral-driven part to identify bias and to discard biased data. A recent study shows that machines are racists about names, when they match European American names with positive words and African American names with negative words more often, and, unless having an algorithm especially dealing with this bias, the same bias always appears (Devlin, 2017). To sum up, without special algorithm aiming at clearing prejudices, artificial intelligence is unable to recognize racial and gender prejudices and to separate them from the original materials, and thus cannot decrease bias.
	In a conclusion, artificial intelligence is unable to clear human bias because it learns from biased materials and it is unable to differentiate biased information and to discard them. Artificial intelligence is desirable, but the technique can be improved further, as in some cases the artificially intelligent machines are still making biased decisions. Therefore, researchers in the field can try incorporating human knowledge with machines to give fair feedback. Further research is also needed to implement algorithms to supervise machines and prevent machines from making biased judgments.

References
Devlin, H. (2017). AI programs exhibit racial and gender biases, research reveals. The Guardian.
Hutson, M. (2017). Even artificial intelligence can acquire biases against race and gender. Science.
