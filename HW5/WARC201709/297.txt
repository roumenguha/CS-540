	The Stanford One Hundred Year Study on Artificial Intelligence seeks to outline the state of current AI research and application, as well as put forward an estimation of the impact of AI on various aspects of society in the coming 15 years.  While the Stanford report covers AI in eight domains, I will focus my response to one of them: healthcare.  Specifically, I will challenge two of the points made in the report concerning AI’s impact on medical image analysis.  
	The report lays out several barriers to advancing the current state of AI systems’ use in radiology.  First, the authors comment on the difficulty of clinically relevant radiology reads: “the problem in medicine is not to recognize what is in the image (is this a liver or a kidney?), but rather to make a fine-grained judgement about it (does the slightly darker smudge in the liver suggest a potentially cancerous tumor?).”  While it is true that small image differences are often important in identifying pathologies, to dismiss organ recognition as an unimportant task is naive.  In fact, one of the largest areas of application for AI in radiology so far has been image segmentation - the careful contouring of individual organs or structures in a medical image.  Segmentation has important applications in several areas of oncology, including the assessment of patient response to various cancer therapies, as well as organ at risk identification prior to radiation therapy.  Without AI, segmentation is either a time-intensive task which requires a highly skilled physician to spend several hours hand contouring anatomical structures, or an automated but simplified task that uses rudimentary image intensity thresholds, or other detrimentally simplistic techniques, to identify structures.   With AI, either classical machine learning or, more recently, deep learning techniques can be trained on physician-analyzed images to produce physician-quality contours without a large time investment by busy doctors.  Nevertheless, AI may also help in identifying “slightly darker smudges” as well, but the clinical relevance of the question, “is this a liver or a kidney?” and AI’s role in answering it should not be overlooked.
	Second, the report comments on several challenges to the creation of large-scale medical image databases for the purpose of training AI systems, including overly-bureaucratic legislation and patient privacy laws, but they fail to state another which must also be considered: data variety.  The number of degrees of freedom in medical image acquisition is enormous.  Even if cooperation between healthcare organizations allows for the compilation of a single database containing all patient images acquired worldwide, the usefulness of that database will be limited by the incalculable variety and poor curation of that data.  Even for a given imaging modality, the number of imaging variables is staggering.  For example, consider a PET scan, where a radioactive tracer molecule is injected to map the distribution of a physiological process inside the patient.  Patient specific factors such as age, weight, gender, and disease type affect the image.  Acquisition parameters such as scanner model, image reconstruction algorithm, tracer uptake time, image field of view, and image resolution also play a role.  Additionally, there is no guarantee of image metadata being recorded at all!  By the time all sources of variation and lack of data labelling are accounted for, the power of a large-scale image database to produce statistically significant findings may be drastically reduced.  In short, yes: archaic healthcare regulations are a source of hindrance in realizing AI’s full potential in radiology, but assuming that red tape is all that stands between the field currently and the full, seamless integration of AI into clinical radiology practice is unwise. 
