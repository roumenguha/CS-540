  “One Hundred Year Study on Artificial Intelligence” stated that transportation is probably the first domain that AI system is widely accepted by the public. However, unlike education or entertainment domains where the decisions AI system made are usually complimentary, any issues AI systems generated on transportation can have severe consequences. For instance, Tesla’s autonomous cars are very popular recently, and they introduced the full self-driving cars, which are even more advanced than the semi-autonomous cars mentioned in the article. Nevertheless, as the article said, the first fatal accident with an automated car happened in 2016. The AI system on the Tesla Model S failed to apply the brakes when there is car turning left in front of it (Business Day, 2016). “One Hundred Year Study on Artificial Intelligence” cited that self-driving cars will be widely accepted by 2020, where the statement can be rejected with the accident referred previously. Compared to driving a car that can become out of control at any time, introducing teaching robots or AI healthcare system seems to be more acceptable. The mistakes made by teaching robots and AI healthcare system can usually be corrected later, but the mistakes are likely to be irreversible. Therefore, it is likely that the applications of AI on healthcare and education will outcompete the applications on transportation, although the latter one sounds much more attractive.  Furthermore, the applications of AI on healthcare can have many problems. For diagnosis, if the result of AI system influence the judgement of the physicians or clinicians, and a false decision is made, then the patient will suffer. There are two types of mistakes: when the patient actually need the treatment but the AI system and the doctor think he/she is healthy, which is so called “False Negative”, result in missing the best treatment time, then there can be severe consequences. Another case is so called “False Positive”, where the patient is actually healthy but the AI system and the doctor mistakenly decide to apply the treatment. For instance, when AI tells there is a cancerous tumor in the abdominal cavity of the patient after analyzing the images, and the doctors believed it after accumulating all the data, but eventually found it is not a tumor— the patient suffers even more than the former case. Usually, the machine learning algorithms requires validation to make sure it functions properly. However, in healthcare domain where wrong diagnosis and treatments can also incur serious problems, how well the AI system can perform is really critical, and we can’t even afford it to have a mistake. It is unlikely that a perfect AI healthcare system can be generated with zero False-Positive and False-Negative rate, which even the most experienced doctor can hardly guarantee.  The patient privacy discussed in the article is another obstacle for the application of AI in health systems. In this internet era, we are benefiting from data sharing, but are also losing the privacy. While the personal health information can be extremely valuable and therefore generating unregulated commercial uses, it is hard to say whether AI applications such as mobile apps will benefit or obsess people more.
521 words