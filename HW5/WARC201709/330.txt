The Stanford One Hundred Year Study on Artificial Intelligence’s greatest failing is the  omission of a discussion on the effect of AI on war waged by North American governments. The risk of new smarter machines making government more dangerous, immoral, and undemocratic is too large a menace to be left out of any comprehensive analysis of artificial intelligence. The most critical example of this danger is the use of unpiloted “drones” to carry out surveillance and assassinations in the War on Terror. This essay will briefly cover the current state of the drone warfare and its impacts, followed by a recommendation about how the One Hundred Year Study should address this issue in the future.
One of the most startling trends in modern warfare of the last ten years in the increased use of unpiloted flying machines known as drones. Indeed President Obama, not known to be especially militant, carried out ten times more drone strikes than his predecessor (Obama’s covert drone war in numbers: ten times more strikes than Bush, The Bureau of Investigative Journalism, 1/17/17 https://www.thebureauinvestigates.com/stories/2017-01-17/obamas-covert-drone-war-in-numbers-ten-times-more-strikes-than-bush, Accessed 9/13/17). These drones strikes, primarily used in countries where the United States was not officially at war, has caused the deaths of hundreds of civilians (ibid). Thus drones are not only used at increasing rates, but to deadly effect. On top of the ease that drones can be used for physical violence, what is especially dangerous is the way they can change the political calculus of war. Thus American politicians are now able wage war with all its horrors (murder, destruction, and terror) without one of its primary political costs (dead American soldiers) (The History of Drone Warfare, The Bureau of Investigative Journalism, https://www.thebureauinvestigates.com/explainers/history-of-drone-warfare, Accessed 9/13/17). How could this not lead to the proliferation of violence abroad? What will the future hold as more sophistical drones are developed: machines that are able to fight and kill, without the input of a human conscience? These are the type of questions the One Hundred Year Study should be addressing.
In order to raise awareness of the growing threat that military drones pose, the authors of the One Hundred Year Study should put ethical use of military AI front and center in its report. Their analysis should include a review of current practices of AI on the battlefield, the costs and benefits associated with those uses, and an examination of future trends, including risks to human rights and democracy.
        The Stanford One Hundred Year Study on Artificial Intelligence does a fine job summarizing the commercial, consumer and research impacts of trends in the field of artificial intelligence. However simply stating that “...military applications were deemed to be outside the scope of this initial report” (p. 3) is unconvincing.  And failing engage with the emerging use of AI and robots by North American governments to wage war is unconscionable. This revolution on the battlefield has direct consequences not only for the unlucky individuals who happen to inhabit Somalia, Pakistan or Yemen but for the politicians who wage these wars and for the public which consents to them. In other words, the very citizens of North American cities upon whom the report sets its focus.