       The article on Artificial Intelligence (AI) by Peter Stone et al. fails to sufficiently address the possibility of rapid advances in the field; which would require more immediate, rigorous regulation. The study panel covered a range of 8, of what they believe are the most important domains related to AI. For each of these domains, including: transportation healthcare, education, and public safety and security, the panel describes the influence of AI to-date and provides information on how North Americans, both collectivity and individually, may influence and be influenced by AI in these fields in the coming years.  The article fails to address immediate action that should be taken to help proactively regulate AI in the case of a faster than expected takeoff. This gap in information could have detrimental effects if the suggested case occurs. Immediate policies should be put in place and study panels formed to specifically study how to regulate AI, to reduce the risk of AI, that is biased, unreliable, or hostile 
         The importance of time is highlighted throughout the paper; however, policy guidelines, suggestions, and other recommendations regarding the immediate term are generally vague.  Statements on the future of AI, in the area of transportation, such as, “The increased sensing capabilities, adoption of drones[…] will also raise concerns about privacy [..], these and related transportation issues will need to be addressed either by preemptive action [..] or within the legal framework” leave questions of what preemptive action needs to be taken, or even how one might start to answer that question, or the question of what an adequate legal framework may look like. In the clinical setting, recommendations become a bit more specific with the use of terms like “free-form dialogue” being used to describe attributes of AI clinical assistants, but still fail to address the underlying ambiguity. Does “free-form dialogue” mean that the same AI assistant that takes my vitals at a hospital, will ask me about my day? Such questions might seem pointless but unknown consequences affecting patient health may arise based on choices made now. 
       Rigorous research on AI and how it will be regulated should be implemented immediately. Multiple incidents in the past few years have called into question existing laws on encryption, privacy, and liability relating to electronic devices. Furthermore, these incidents highlight the inadequacy of current legislation’s ability to effectively regulate the technology of today. If this legislation is not sufficient now, how can it possibly be sufficient for AI?  The suggestions offered by the study panel will be effective assuming only that we have studied AI well enough to be able to regulate new technologies as they are released. This reactive rather than proactive model could very well fail if new computing technology advances at a rapid pace. Recalling Moore’s Law (the Law stating the doubling of transistors about every 18 months) and the general trend of innovation in the technology sector in the last few decades, this scenario is not at all unlikely.
        A critic of increased regulation may claim that regulation created now will become outdated quickly if AI does advance rapidly, and may be more likely to hinder AI advancement. While the critic may be correct in guessing that legislation could slow AI advancement in the future, without adequate legislation government and private researchers, companies, and citizens alike may fail to react quickly or correctly enough to advances in the field. If an artificial intelligence becomes sentient, is it then legally responsible for its actions? If it is not who is responsible for an artificial intelligence created by an open source project? 
       
       



