
The 'Artificial Intelligence and Life in 2030' study provides an informed guidance on AI research, development and its influence over a range of domains. AI continues to deliver important benefits in our daily lives, playing a crucial role in transforming the way we live by making driving safe, helping children learn and find interactive and personalized entertainment sources. However, there are a few instances where the study does not present a clear understanding of what might happen in future and ignores a few challenges in specific research domains.

Transportation is one of the domains which is going to be completely autonomous in near future. A recent, highly appreciated move by Tesla, an American automaker company, where they pushed an over the air emergency software update to increase the driving range for its vehicles in Florida to help vehicle owners get away quickly from the wrath of Hurricane Irma, depicts the strength possessed by AI enabled devices and its growing demand in near future. However, this points out a few shortcomings, also ignored by the study. 

Will the corporations experimenting AI systems make ethical decisions in case they are given the authority? Will AI systems fall in good hands? This reflects a dire need of a regulatory system that would intervene if a bad decision is made in an emergency as it has the potential to be used for good or nefarious purposes. The study affirms the existence of a regulatory system, but ignores its immediate need and fails to recognize the government reaction speed as compared to the advancement rate in AI.

The study neglects the safety and backup options in case of a disaster. It assumes that ideal conditions would always exist for AI systems to work. The vulnerability of AI systems to a natural or manmade disaster is unknown. Is there a possibility that the AI systems will completely shut down. There is no evidence if we support such infrastructure which enables an ideal environment for AI systems at all times or whether the government is willing to provide sufficient funds for such research in AI.

The study understates the fair distribution of AI. Distribution of wealth is unfair and hence, weaker sections of the society might not necessarily afford the AI systems. A fair policy can be formulated so that everyone enjoys the benefits of AI. Another concern that arises from the study is that who should be held accountable, in case a self-driving car crashes, an AI system fails or makes a bad decision. A system which can assess the safety, privacy, fairness and other impacts of AI is required.

The study overstates that AI will create a pool of jobs as compared to the ones it takes away. AI will definitely create new jobs, however, these jobs would be new categories of employment, requiring special skillset. AI systems are going to do everything better than humans. AI success also depends heavily on the trust humans put in using the AI system, which can be slower.

The study does not provide a way to eliminate human bias, which might creep in due to predictions of likelihood from previous patterns (including human bias). It also raises privacy issues, where factors like race, color and sexual orientation affect the decisions taken by the AI systems. 
The aim of AI is not to add friction, but add value to our lives. The study can reflect on the arguments and make new assessments, regulatory customs and policies for optimum utilization of AI.
