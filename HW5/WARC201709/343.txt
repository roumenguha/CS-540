AI has been developing significantly over the past few decades in many fields, and its application can be seen almost everywhere in the world. In the article One Hundred Year Study on Artificial Intelligence, many applications and future blue prints are mentioned. Although various kinds of excellent thoughts are expressed throughout the paper, there might also be some flaws within the analyses that are worth considering. In this essay, I would like to challenge one point made by the authors. In the field of Education, the authors state that minor utilization of sophisticated AI technologies across schools and universities results from shortage of financial resources and lack of data that are used to set up effectiveness of technologies. Instead, I think the reason is that AI cannot subjectively infer the attitude of students or the actual level of mastery of knowledge of students to provide targeted personal learning plans.

First of all, AI has not necessarily featured complicated subjective inference so far. Humans can subjectively complete inferences in a miraculous way. For example, if my friend and I were to set up a meeting time, I would be likely to say, "let's meet at 4 o'clock." Here comes the problem. Would my friend come to meet me at 4 am or 4 pm? As is known to all, people are usually asleep at 4 am, so it is not likely that my friend would meet me at 4 in the morning. Instead, 4 pm is an ideal time to meet. Thus, my friend would definitely come at 4 pm for the meeting. However, how would a computer know whether the meeting is at 4 am or 4 pm? If the AI was programmed using 24-hour clocks, would it just assume the meeting time being 4 in the morning? Someone may argue that it is easy to include such logic when programming AI technologies - people just need to feed a large set of daily life conversations to machines and let them figure out what to do. Nevertheless, what if the logic behind becomes complicated? Will AI technologies still be powerful to figure out the inferences quickly and accurately? I believe this remains to be questioned.

Since AI is not necessarily powerful enough to deal with complicated subjective inference according to what is mentioned above, AI technologies implemented in the field of education cannot tell whether a student really wants to learn, or whether a student needs a different learning plan. Especially at school, some kids do not like studying at all. Teachers can tell whether their students want to spend time studying or not easily through observing students' words and actions in daily life. However, AI machines cannot have access to enough information to make inferences on whether students are interested in studying by only recording their actions on the screen while they are doing homework. Such inference must be made through a huge set of data collected from each student's daily life. Therefore, so far only teachers can really provide targeted personal learning plans effectively enough for students' future development.

Admittedly, AI technologies have been developing rapidly in recent years. The reason why so few AI technologies are used in schools and universities is not due to lack of either financial resources or data collection. Instead, it is the lack of ability to perform complicated inference that hinders AI being wide-spread. Only when AI machines can perform inference upon what students' attitude is towards studying and personalize individual learning plans accordingly without using too many data can AI technologies replace the work of teachers in schools and universities.