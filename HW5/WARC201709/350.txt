The Stanford One Hundred Year Study on Artificial Intelligence (AI) provides an expansive look at the current research/uses, trajectories of research and development, and misconceptions about AI, as well as suggestions for future policy proposals to help guide informed regulatory practices over such technology. As a whole, the review provides a rational framework by which we can begin to tackle the challenges of emerging technologies from both personal and societal perspectives. One area of particular interest to the committee is the implementation of regulations that, from the authors’ standpoints, can provide safety and privacy oversight, but also have the potential to stifle innovation in both the public and private sectors. Although the authors’ are clear that regulation should be evaluated on a case-by-case, sector-by-sector basis, they make potentially dangerous assumptions about particular regulatory bodies and policies, in particular the Food and Drug Administration (FDA) and the Health Insurance Portability and Accountability Act (HIPAA). More specifically, they tend to overlook important issues regarding patient rights and privacy that are of utmost importance to the future of health care and health care-related technologies. 
	AI has the potential to revolutionize how we diagnose and treat disease, based on the increasing ease of health data collection and storage on a mass scale. However, as this ease increases, so do concerns about maintaining patient privacy and a patient’s right to have their personal health information (PHI) removed from mass storage and use for research. The report states that “Research and deployment have been slowed by outdated regulations and incentive structures” (p. 25; under “Healthcare”), which is laden with potentially false assumptions about not only the motives of professionals in the health care industry, but also with regard to how often regulations are updated. Without an exhaustive review of current regulation of and potential financial conflicts of interest within the healthcare industry, such speculation is dangerous and may increase the chances that patient rights may be infringed at the behest of innovation. The report also states that “Unfortunately, the FDA has been slow to approve innovative diagnostic software, and there are many remaining barriers to rapid innovation. HIPAA … requirements for protecting patient privacy create legal barriers to the flow of patient data to applications that could utilize AI technologies.” (p. 27; under “Healthcare analytics”), a claim made with neither citable nor anecdotal evidence made in its defense. Health care regulation, and the process by which it is changed, is made to be slow and incremental by design due to the severe consequences of making fast decisions without deliberate thought of the unintended consequences. When patient’s safety and privacy are at stake, decisions should not be made in haste based on what the author’s deem as “rapid innovation”. Instead, thorough testing of PHI-utilizing applications should be conducted in order to maintain the highest degree of patient safety and privacy.
	Although the authors do point out potential issues that significant health regulations may pose, including the risk of higher rates of misdiagnoses and inappropriate treatment, as well as no regulatory body to govern the sharing of PHI from institution to institution (p. 27; under “Healthcare analytics”), this doesn’t therefore mean the industry should forego important regulations underlying patient privacy. These issues should, of course, be evaluated case-by-case, however the authors should avoid lofty and potentially misguided suggestions about the health care industry as a whole and make specific policy recommendations if they feel regulations are too strict and/or are in need of revision
