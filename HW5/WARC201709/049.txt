	All of the AI computer programs we have nowadays are actually weak Artificial Intelligence that could only focus on one narrow task. Human can easily control them because their performances are based on the programs that programmers wrote. For example, Alpha Go and Siri. The conversation Siri could make are based on a limited pre-defined range, and it does not have self-awareness. Alpha Go, the same as Siri, are designed only for beating professional Go players. However, the research “Artificial Intelligence and life in 2030” (Stanford University, 2016) mentioned that the scientists want to really make AI intelligent, also known as strong AI, a machine with consciousness and with the ability to apply intelligence to any problem, rather than just one specific problem. As the result, there is no doubt that AI robots and machines would replace most of the works in the job markets without restrictions in the near future, and the article addresses the importance and restrictions on the use of AI in the job markets. What’s more, the study group also plans on setting a series of principles and moral standards that all AI machines’ designers need to follow to prevent strong AI from going out of the control of human or surpassing human, just like most children are smarter than their parents. However, does everyone really think strong AI could follow the principles and moral standards designers set for them once they have their own consciousness and self-awareness? Unlike the view of the research, the answer for me is definitely no!	AI are designed to perform faster, better, more efficient, and more accurate than human, and they are all designed by people with high IQ. In the whole article, the scientists’ whole conclusions are based on the premise that “AI must not do something dumb” or “AI must not harm human beings and the society”, but an intelligent AI machine with self-awareness will unlikely to follow the principles in reality. Parents can not prevent their children from falling into a wrong path although parents taught their children they need to be honest, kind, brave and etc. when they are young; AI follows the same logic: the programmers put certain principles and ethical restrictions in the programs to point a right direction for AI programs, but they forgot strong AI programs have their own thoughts and self-awareness, which means “it” could has a chance to fall into a wrong path. The worst thing a people could do is kill others, and it is hard for one or several of them to harm the whole society, but strong AI really can, just as the concern Elon Murk mentioned in Tesla’s conference call with its investors. Then there is no way people could beat a machine that is a lot smarter than human’s elites. 	From my own perspective, the initial motivation of using AI to raise the standard of living is good, and we should take advantage of it. However, the scientists and politicians should be aware of the harm of over confidence on AI or strong AI, more precisely. Reference: “One Hundred Year Study on Arti cial Intelligence (AI100),” Stanford University, accessed August 1, 2016, https://ai100.stanford.edu. 