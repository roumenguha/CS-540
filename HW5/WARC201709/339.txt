The issues that I found with the One Hundred Year Study On Artificial Intelligence article is that, specifically on the subject of healthcare, it fails to address the topic of limited data sets. On page forty nine, the article says that many advancements in AI come from “growth and analysis of large data sets enabled by the Internet, advances in sensory technologies”, and deep learning. What this overlooks is that sensory technologies, no matter how advanced, will only see what we are using them to look for.
Current datasets that can be pulled from health services are limited in many ways. The article specifically mentions how the FDA and HIPPA are barriers to accessing data, but a much more dangerous one is that often times, the data will not exist. Due to the precise nature of medicine, when the article says that there is an extensive record of patient scans, it means very little. In medicine, unlike web-browsing, only the minimum that is thought to be necessary is done.  Doctors simply can not ethically or practically take note of the entire state of being that their patient is in. In the case of cancer that is mentioned in the article, we only have what we already know causes cancer in the scans. This means that we have very specific images of very targeted areas that a specific doctor asked for, there isn't a full workup, including unrelated statistics, of each patient who comes in for cancer treatment. For all we know, oils in the hair or something else seemingly unrelated to cancer could be beneficial to AI testing for cancer, but that data simply does not exist as doctors cannot make use of it and so it isn't collected. 
This is a limitation that is unique to the medical field. When programming a driverless car, you can attach as many cameras as you think is necessary to achieve the goal of "not crashing". This creates an absolute wealth of information from which to build and with which to decide how to move forward. In medicine, the information that you can gather is limited by the patient and by the doctors gathering the information. Fortunately, when looking at more granular AI this becomes less of an issue.
In the article there is no mention of this human constraint to AI where it becomes limited not by what it can be trained to do, but by what humans have already discovered. Yes it will be able to increase the rate of correct diagnoses in patients, but it will not be able to take that next step and improve.
One other issue is when dealing with health AI is that many issues present themselves indistinguishably from each other. The hope of having an AI in a mobile app that can help with preventative measures is flawed. There are not ways of measuring human physiology in a precise enough manner to be useful. Unless the mobile app will have the authority to order more tests move people to a hospital to get said tests, it will be unable to collect the data necessary to have a meaningful impact on the lives of its users making it commercially inviable. Ultimately this article fails to deal with the issue of non-existent data in medical and that the cost of obtaining it is likely to be more prohibitive than legal barriers.