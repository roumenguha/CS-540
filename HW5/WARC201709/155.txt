CS 540 h1	The Stanford One Hundred Year Study on Artificial Intelligence is an in-depth report about the current state and the future of artificial intelligence. It discusses current ethical and technological issues in the AI sphere, along with what work is being put in to develop AI technology into what would be in the best interest of humankind. 	While reading this report, I tried very hard to spot bias and possible skewed data in order to find a point to challenge. This proved itself to be a difficult task, considering that while the article has an optimistic view of AI, it also discusses its flaws and potential dangers. The article reads, “As with self-driving cars and other new transportation machines, the difficulty of creating reliable, market-ready hardware is not to be underestimated” (24). They have a similar stance with every AI subcategory mentioned in the article, so I would argue that they have a very realistic view of the future of the field. After reading the article, I have decided that there is only one point that I feel I could challenge: the inability of AI to become a threat to humankind. 	The report is prefaced with a statement that denounces the view of AI as seen in movies such as iRobot, the Matrix, or other dystopian tales where artificial intelligence attempts to take over humankind. On page four the report reads, “The Study Panel found no cause for concern that AI is an imminent threat to humankind. No machines with self-sustaining long-term goals and intent have been developed, nor are they likely to be developed in the near future” (4). While I believe that AI is the future of success in healthcare, transportation, and quality of life in general, I also believe that the continuous development of AI may pose a threat to the wellbeing of humankind. However, my idea of a “threat” is different than what the article denounces. I believe the threat of AI comes down to a more socioeconomic view, and that artificial intelligence has the ability to widen the socioeconomic gap between humans. 	In the U.S. we struggle with inequality between the rich and the poor, and how to contract the gap. We are also in an era with an extreme political divide, where conservative and liberal are practically polar opposites. As artificial intelligence development is on the rise, there are many skeptics who do not want to adopt this technology into their lives. Doctors’ offices, for example, are divided between those who use paper records and do everything the “old-fashioned way”, and those who use electronic health records and predictive medical analytics with their patients. The doctors’ offices that refuse to use innovative technology in their practices are falling far behind the others, and the gap between the two increases with each technological medical breakthrough.       A statement that stood out to me while reading is as follows, “AI technologies could widen existing inequalities of opportunity if access to them—along with the high-powered computation and large-scale data that fuel many of them—is unfairly distributed across society” (10). While I agree with the previous account, I believe that AI technologies might widen existing inequalities of opportunity because humans make personal decisions not to have access to these devices. My fear for AI is that there will be a divide between those who welcome innovation and change, and those who want to live their lives in a more traditional manner without the interference of artificial intelligence. Our country is already divided by those who believe we should build a wall and by those who shouldn’t. Imagine a country divided by those who adopt an entire field of technological innovation into their lives, and those who don’t.        