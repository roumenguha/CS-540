	The essay “Artificial Intelligence and Life in 2030” was developed by a panel of many of the most prominent figures regarding AI research and knowledge in the world. It provides an overview of where AI was, its current state now, and what we can expect moving forward in the next thirteen years. While the article is surely thorough in its analysis of how AI will affect our lives in the coming years, it fails to address many of the negative possibilities that could arise from military applications should AI take on a larger role in our everyday lives.
	While the article states very briefly in the beginning that is does not aim to “minimize the importance of careful monitoring and deliberation about the implications of AI advances for defense and warfare (1)”, at no point after that does it mention the what the possibilities or advances are regarding this topic. AI is thought to be a revolutionary tool in warfare and military settings with potential for a wide array of uses. Russia has announced that they are developing a drone that can locate specific targets and make decisions via machine learning algorithms themselves (2). The CIA is developing tools to track an individuals posts on social media (3). These are just a few applications of how AI could be used in a military setting. Many other applications and developments could be currently being researched or even implemented without public knowledge.
	While these technologies hopefully will not pose an immediate threat to society, it is largely possible that the future of warfare will revolve around the use of AI in machines and weapons. Luckily, some countries have come out in support of banning fully autonomous weapons, most recently the U.K (4). But there has still been no conclusion reached by the UN, and lots of countries, including the US, still have not issued a strong statement regarding this issue. Furthermore, we already see a prominent use of AI powered drones in warfare today. It is estimated that the U.S. killed 200 people between January 2012 and February 2013, and only 35% of those people are believed to be the intended targets (5). Without discussing the regulation and enforcement of AI powered weaponry, we can only expect numbers like this to increase.
	Once can hope that these issues may not becoming pressing to the general public in the near future, there is a possibility that many citizens could be affected by some sort of military sponsored AI, even without being aware of it. While many tech companies consider themselves very ethical, there are people and organizations that could use these technologies for the wrong reasons. The sudden growth of AI in military applications could pose great threats to society if not properly secured and monitored with societies best interests in mind.


Sources
1. https://ai100.stanford.edu/sites/default/files/ai100report10032016fnl_singles.pdf
2. http://www.zdnet.com/article/uk-bans-fully-autonomous-weapons-after-elon-musk-letter/#ftag=RSSbaffb68
3. http://www.ibtimes.co.uk/cia-developing-ai-that-could-track-your-social-media-posts-gather-intelligence-1638881
4. http://www.zdnet.com/article/uk-bans-fully-autonomous-weapons-after-elon-musk-letter/#ftag=RSSbaffb68
5. https://www.theatlantic.com/politics/archive/2016/03/the-obama-administrations-drone-strike-dissembling/473541/