This document challenges the claim that the study has noted effects of AI in entertainment domain in recent years by providing examples conspicuously absent from the study.
Involvement of learning technologies in entertainment have increased over past few years. Rightly said, few can imagine their daily lives without internet now. But for these learning technologies to work, they collect user information and store it as profiles on servers. This raises the obvious concern of privacy, and as has already been demonstrated by many hacks in recent times, the security protocols are not infallible. Such profiles when available to those with negative intentions, can lead to ID theft. An extreme case is of the recent Blue Whale game, where admins use this personal info to intimidate teenagers to complete 50 tasks, last of which is to commit suicide. 
Facebook’s Graph search algorithm became very lucrative a few years ago. The reason being that it provided a straightforward interface to search and narrow down a profile. One can even find profile of someone they crossed on the street that evening by feeding in parameters like city, gender, time and place of encounter etc. This led to stalking becoming child’s play in communities where youngsters put all their interactions online. Cases of thefts were also reported where burglars knew when the owners were not home, from their social media profiles. Use of intelligent software and machine learning, especially in domain of social media and entrainment, is growing faster than the pace of policy and cyber security.
The paper acknowledges that humans have responded to AI driven entertainment surprisingly quickly and raised concerns of reduction in interpersonal interaction among human beings. We have more reason to stay in touch with our phone, where we have the whole world at our finger tips, rather than talk to the next guy. Getting more likes and re-tweets has become quite a craze because it is frequently attached to one’s “self-worth”. Pouncing on this opportunity are several online markets using learning software to provide “tactics” for improving their likes or re-tweets. These raise a few ethical concerns of whether such dependence on machines be encouraged.
Personal assistants are available on every modern phone. They collect, store and analyze huge amounts of personal information and usage statistics. Apart from the question of security, raised above, there is also the question of how far these assistants can go on to replace human friends/family. With time, these assistants can coalesce more information than even the closest relationship, making good on the “personal” aspect. This can provide the user a false feeling that the piece of machinery in their hands understands them better than the human counterparts. But these assistants are still far from providing assistance in a way a human can. It’s not easy to diagnose stress, depression or other mental problems for a machine. They also can’t yet provide useful advice for example when the user may be suffering from a loss. Yet they can do a pretty good job of marginalizing human relations that could have been helpful in these situations. 
Overall, AI has dominated entertainment for a while now. It has been great at creating business but sometimes also raised ethical and health problems. The examples highlighted above should be accounted in the AI’s 100-year study.
