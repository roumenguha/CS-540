One thing the study mentions is the collective trust of society in AI and how it can threaten the advancement of AI in the future. At the same time, the report continues to convince the audience that by the year 2030, the typical North American city will have completely transformed into one including AI technologies we never imagined would take over. I am challenging this notion of the report because I believe that even if we are able to come up AI technologies that solve many of our problems, we are restrained by the people. I believe that as humans and creatures of nature, we naturally distrust each other and because of this, we will not trust the AI technologies—not because we think they’ll attack us like in the movies, but because we can’t fully trust that the people who built these technologies do not have malicious intents.This, of course, is the case for any new technology, and that is why we have been focusing more on security on these technologies. But because the potential of the AI technologies mentioned in the report goes beyond just a smart phone or credit card machine, people will be more cautious than ever with these technologies. These AI technologies have the potential to capture private information about you that can be used for blackmail, inform you of the wrong material in harmful ways, and more. Many of these concerns outweigh the benefits of the technologies.Like the report states, different areas of AI applications have excelled more than other areas. The difficulty to trust the new technologies of AI will come not from the belief that AI will fail but from the mistrust humans tend to have on each other. For example, how can we be sure that the developer of an AI system aiding in medical circumstances has the right intentions? If the robots are so “intelligent,” wouldn’t that make them smart enough to deceive humans? This will not be for the benefit of the robot but for the benefit of the developer of the device that is doing the deception. The point here is that humans are the ones that are performing these malicious acts, and my concern with the report is the picture it paints for the future of AI for 2030. I believe that it will take way longer to get humans to accept AI than what the report suggests. There’s also the problem of hackers with malicious intent. They may be able to hack AI systems and cause harm to humans in many of the ways mentioned in the report. 2030 is an ambitious goal for many of the technologies mentioned in the report not because I think we won’t be able to build these systems but because naturally, humans will not be willing to accept it. There needs to be extensive testing and security measures taken in order for many of these technologies to gain popularity in the public. This will push back the date in which we see a world dominated by AI technologies. For these reasons, it is hard to imagine that many of the potential technologies that AI enables to deliver will come in 2030.