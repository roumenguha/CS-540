I challenge the study's assumption that autonomous vehicles will become commonplace by 2020. In fields like healthcare and education, AI is largely self-contained and does not have the potential to create troubling scenarios as it does in autonomous driving. 

While capabilities like perception, GPS and the plethora of sensors driving the AI might make a very good driver indeed, it raises thorny ethical questions. When it comes to an inevitable situation, how does a vehicle decide between saving the life of its driver and that of a pedestrian? How should a vehicle choose between its driver and that of ten pedestrians? In case the car decides purely based on the number of lives put at risk, would a potential customer still be willing to purchase the vehicle given that the car might sacrifice his life if it comes to the worst? The study also mentions self-driving trucks becoming the norm soon. Would businesses be willing to transport precious cargo with the knowledge that it might be destroyed in case the truck must choose between the cargo and a life? All these arguments have been largely quantifiable in terms of lives. How do we handle when a vehicle must choose between its driver and another vehicle on the road, where the distinction between the number of lives is less clear? 

Given that an AI developing compassion, valuing a life and other human emotions is still far off, it falls to the manufacturer and its engineers to decide what the vehicle must be programmed to do in these scenarios. Mercedes for instance has publicly made a statement that its autonomous vehicles will prioritize its occupants over any pedestrian [1]. On the same lines, a truck manufacturer might be willing to prioritize the cargo over anything else. This implies that all autonomous systems must be heavily regulated much like other industries and making every vehicle in the country conform to this regulation would a long endeavor and not something achievable by 2020. It also opens the question as to what happens to those citizens who choose to drive by themselves rather than adopt to self-driving vehicles and how they fit into the system given that the roads are common and will be shared. 

Thereâ€™s also the issue that these are real time, life-critical systems and given that the automobile manufacturers thrive on annual servicing, we will have to deal with problems like sensor malfunction and security threats. A recent study also concluded that 75% of drivers do not feel comfortable putting their trust into a machine and they fear that they will be forced into a position of being unable to seize control from the car in case of any unforeseen circumstances [2]. We will also have to confront potential fallout from the loss of jobs this would entail as millions of truck drivers in the United States would lose their livelihood. 

Given that this topic is currently being debated by the senate [3], it might be worthwhile to consider these questions while drafting a bill such as this with far flung consequences. 

References:
[1] http://www.futuristgerd.com/2017/08/27/why-mercedes-decision-to-let-its-self-driving-cars-kill-pedestrians-is-probably-the-right-thing-to-do-says-bloomberg/
[2] https://spectrum.ieee.org/cars-that-think/transportation/self-driving/driverless-cars-inspire-both-fear-and-hope
[3] https://www.reuters.com/article/us-usa-selfdriving/senators-unveil-road-map-for-self-driving-car-legislation-idUSKBN1942QJ

