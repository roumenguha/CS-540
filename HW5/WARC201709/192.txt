	Within the Stanford One Hundred Year Study on Artificial Intelligence many budding and already realized technologies are discussed.  One of the technologies mentioned many times is the idea of using artificial intelligence to seek out and potentially prevent crime while simultaneously checking itself for and eliminating biases.  While this does sound like a best of both worlds type of situation, I simply do not believe that it is possible for these two ideations to coexist within a system.  Besides the fact that the idea of having artificial intelligence try to prevent crimes is already a disaster waiting to happen, attempting to implement that and a self-checking bias eliminator at the same time seems extremely counterintuitive.
	If a machine were to be programmed in a manner as to be able to spot “potentially illegal” activity, what would the machine be told to look for?  There are many options that could be put in place, such as where a person is, how they are acting, what they are wearing, or what they have in their possession at the time.  While all of these things may be able to help an artificially intelligent system decide the probability that this person is going to commit a crime, the judgement based off of these is already an inherently introduced bias.  Some people may say that as long as the machine does not use descriptors such as skin color, sex, etc. to decide who may be about to commit a crime, then there is no harm done, but that is simply wrong.  Regardless of what descriptors are used to run this system, many groups of people would get discriminated against and falsely accused of being about to commit a crime.
	Now, after programming this machine, with its inherent biases determining who is most likely to commit a crime, imagine proceeding to write a side program that is supposed to catch when the machine has a bias and eliminate it.  Doing so would eliminate the only guidelines given to the program.  Essentially this artificially intelligent machine would be caught in an infinite battle with itself deciding how to determine who is most likely to commit a crime, then that thought getting immediately deleted after being caught as a bias.  This is not an effective use of one of the most promising fields of science and computing to date.
	Overall, it is easy to see how this application of artificial intelligence in principle is a great idea.  It is disappointing, however, that there is no real way to implement this technology without singling out a group of people or basically having no effect at all.  Researching this technology seems to be a waste of time, money, and manpower.  I imagine the difficulty of implementing this system will be very quickly realized, but I do believe there was one good idea amongst all of this.  Instead of trying to focus on predicting illegal activity, using this technology to simply detect bias and eliminate it wherever possible would be an incredibly productive application of artificial intelligence.  
Eric Christianson
CS 540

