	In the "One Hundred Year Study on Artificial Intelligence" published by Stanford in 2016, the authors have discussed the development of AI over the decades and its promises for the future. The report details many upcoming use cases of AI, the technology needed for successful implementation and obstacles facing these upcoming technologies. One particularly interesting aspect is that of self-driving vehicles that can also navigate autonomously. However, the report only considers the tech side of things and ignores the bureaucracy needed to implement such a change.

	Stanford’s report predicts that mass adoption of self-driving cars will begin in 2020 but fails to acknowledge the time needed to successfully establish a set of regulations that govern the existence of such cars on the road. A whole new set of laws need to be conjured before the dream of self-driving cars can become a reality. Currently, the Department of Transportation(DoT) handles the rules that govern how a car is built and the states control the traffic laws, insurance and licensing. The problem with this structure arises in the case of self-driving cars because the manufacturing controls how these cars operate. This problem is compounded because the technology is nascent and vague. Self-driving cars don’t really exist yet, at least not market-ready autonomous vehicles. It is incredibly tricky to write laws for almost anything, let alone for something that most regulators do not fully understand. That is why it is naïve to assume implementation of self-driving vehicles will not be hindered by slow bureaucrats.

	Another issue that plagues everyone’s minds regarding this technology is the blame game that will ensue if something does go wrong. Autonomous vehicles are being introduced to dramatically increase overall road safety, however, things do go awry. Crashes and other accidents cannot be attributed to human error and litigation could potentially stall this technology. Car manufacturers will not release self-driving vehicles until they are assured of little to no liability in freak cases. It will also be hard to ascertain which car was responsible if the accident involves multiple vehicles. All the parties involved would try to distance themselves from any blame and it would be impossible to pin-point the blame on anyone. The report by Stanford highlights one such incident where a fatal crash involved Tesla’s Autopilot system. Recently, an investigation conducted by the National Transportation Safety Board(NTSB) found that the software played a key role in the crash. They found that it did not define stricter constraints for drivers and allowed them to get distracted easily. The policies that exist right now are voluntary and merely guidelines for corporations to follow. The oversight in this department is severely lacking and automakers have time and again proven that they cannot be trusted to protect public interests in their race for profits and domination.

	Self-driving cars are definitely the future but that is all they are for now: the future. Any dreams of autonomous vehicles driving you to work are just dreams for now. There are potential solutions to the problems mentioned, however, research shows that mass adoption of self-driving cars is still decades away.
