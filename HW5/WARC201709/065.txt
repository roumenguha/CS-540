Artificial Intelligence has the potential to re-define how we receive an education, our healthcare, our politics, and the way we live. While the Stanford One Hundred Year study on Artificial Intelligence has only just begun, in its report there is much speculation as to what the future may hold. This report focuses mostly on the positive aspects of artificial intelligence, and the lack of concern for the regulation and safety regarding this area of technology and it's data is apparent.
	Education has come a long way since the computer was introduced to the classroom. Essays are now typed within minutes instead of being hand written in hours, and online classrooms are now more prevalent than ever. Although artificial intelligence promises to enhance education, there are considerable risks to using automated teaching. For one, how effectively will artificial intelligence be at addressing individual students’ needs and learning abilities? At the core of the problem is data collection. Will these children’s learning data be protected from possible manipulation from outside pressures? Will machines be able to build metrics defining a child’s intelligence? The risks associated with such large scale data collection on children and the potential for misuse are extremely high, both by our government and other third party entities. 
	Healthcare is another area that shows promise for advancement because of the integration of artificial intelligence into healthcare technologies. But do the benefits outweigh the risks? Data based monopolies are becoming ever more prevalent, especially in regards to healthcare. For example, Deepmind, owned by Google, has relationships with Healthcare service trusts in Great Britain which has provided it access with millions of peoples medical information. How can this data be kept safe? Is it even ethical for Google to be using this data to build their own products? The arrangement that Google has with the UK is reporting to have actually broke their privacy laws, and patient’s consent had not been received for this miss-use of their personal information. In the U.S, any of sort of AI system would also have to meet HIPAA standards, which could make working on the machine learning algorithms for patient diagnoses a potential violation as well. Overall, there are many risks that AI and big data cause for the general population, and stricter management and regulation should be put in place to ensure that innocent people are not put at risk. 
	The final biggest problem with AI that wasn’t covered in the Stanford report is the risk to politics. With machine learning, AI will eventually be able to predict elections, unrest, and political turmoil in the future. That in itself is not bad; it’s how this information is used that could be potentially dangerous. If an AI has the ability to predict elections, it must have access to an extremely large data set of information pertaining to individual voter’s political affiliations and their views. If this information found its way into the wrong hands, it would be possible to negatively influence global politics. For example (a wild example), if I knew that in our current situation, a British citizen would one day become President of the U.S, and my AI tells me a certain subsection of the population would be the reason such a thing to happen, I might be inclined to take action against that subsection of the population. 
	Overall, AI promises to redefine the way we live. However, care must be taken so that it doesn’t become a weapon to oppress.
