In “Stanford One Hundred Year Study on Artificial Intelligence”, the authors point out that different from the past, today, we human-beings are on the way to establish “human-aware and trustworthy intelligent systems” instead of simply trying to make the systems intelligent. Nevertheless, I think we are not there yet. In my mind, people are still making progress to build more intelligent systems and machines. The majority of machines or systems are not intelligent enough today. Many of the products people built are not capable of interacting with people smoothly, which in my mind are not intelligent enough. For example, the voice assistant Siri on Iphone sometimes fails to give coherent answers or gives same answer for different questions. The types of questions it can answer correctly are limited. Besides, in the field of robotics, people are still at the stage of making effort to produce robots that can act like real human-beings. We hope that we can create robots that are able to communicate and interact with people. Thus, I think nowadays, people are trying to build intelligent systems though the systems today are much more intelligent compared to those in the past. Furthermore, although we might produce some machines or systems that seems intelligent, we do not fully understand how they work. Machine learning is an example. Driverless cars are regarded as one of the most intelligent applications of machine learning. In order to let those cars drive themselves, people collect a large amount of raw data to train those cars. However, the learning phase is still a black box to us, which means human beings do not actually know in what way the cars learn from the data to drive without drivers. The fact that we do not know how those systems actually work makes it extremely difficult to build systems that are trustworthy. The more we make use of these technology, the harder we are able to create trustworthy systems. Though the driverless cars function well at the most time, we are unable to reach the state of real driverless. This has two reasons. First, even the newest driverless cars will meet some emergencies sometimes and need people to take over the control because there are infinite possibilities of accidents that can happen in reality. Second, since people are not clear about how those cars learn the skills, we cannot truly believe them. We do not know how they drive themselves. We do not know why they suddenly break down either. Therefore, it is hard for people to guarantee the systems are trustworthy even though they might fail only once among all the time they execute. In conclusion, instead of shifting to the stage of building trustworthy systems, I think we are still endeavoring to create systems that are intelligent enough to interact with us freely. Also, because of the situation that there are some fields where people are unable to make sure how those systems learn or work, it is a challenging task for people to build any real trustworthy systems in the near future.