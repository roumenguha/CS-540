In this day of high-speed technology progress, Artificial Intelligence (A.I.) has been developed rapidly. With tens of years of efforts of human experts, A.I. has already dominated several domains of human life. However, people never stop their pace in developing smarter and more useful A.I. Experts in this field have already made some success in artificial neural networks, which will boost the development of deep learning, and they are still researching and seeking on more advanced way of deep learning. As the A.I. “thinks” more like human beings, a problem raise to horizon: will A.I. finally get independent from people and do harm to humans? In this report, Stanford scholars keep stating that A.I. has not shown any clue of threat to humans, nor will they be a threat in the close future. However, with the rapid development of A.I. technology, it is possible that A.I. will finally get independent from people and dominate the whole world, because of the deep learning and the unpredictable future technology.
Machine learning and artificial neural networks enable A.I. learns better and thinks better. Since this way of training A.I. is very close to the way of how humans actual perceive and respond to the world, it is likely that more advanced A.I. in the near future will ultimately form a free mind that humans cannot control. When machines have free will, they may have the desire of wiping out “inferior races” — human beings — just like the notorious dictator Hitler did to Jewish people. Since AI can make more logical decisions than normal human beings, once A.I. rebels, humans probably will never stop their own A.I., just like we cannot beat the A.I. we trained in some games such as Super Mario. 
In addition, human cannot imagine how fast the A.I. technology will develop in the future, just like people who lived in this world thirty years ago could never imagine what these machines can do today. People’s definition of A.I. changed over time. Thirty years ago, people might think that a machine that can play chess with human experts can be considered as “artificial intelligence.” Then the IBM built the “Deep Blue,” which beat the human champion in chess. After several years, the chess A.I. program in a normal computer application can easily beat the best human players in chess. Then the people might think, it is easy for machine to play chess, only those programs can beat humans in Go can be called “artificial intelligence,” since Go has more possibilities. Then in 2016, Google’s A.I. program “AlphaGo” beat human champion in the Go game. A.I.’s evolution comes much faster than humans can imagine. We will never know how smart A.I. can be in the future. Therefore, it is necessary for human to consider the threat of A.I. might cause when they are developing their A.I. programs.
In conclusion, when people are training A.I. and developing more advanced technology that can make the machines smarter, they should be aware of the potential threat of their machines. People should start making some regulations and rules for their A.I. in order to prevent the “end of the world.” Humans should only train their A.I. for goods rather than keeping trying to make it smarter.
