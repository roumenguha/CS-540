      Although Stanford’s One Hundred Year Study on Artificial Intelligence (AI100) presents a rather optimistic prediction for the futuristic Artificial Intelligence (AI) technology on the horizon from a high-level, computer scientist’s perspective, the technical report is too vague and insufficient with respect to computer hardware, which lay the foundation of all AI and could stymie the emerging of new AI technologies.      As the technical report mentions, AI in the future will rely heavily on large amount of data to make predictions and carry out sophisticated tasks. With current burgeoning AI research and investment, it is reasonable to believe that computer scientists will develop new AI solutions in the near future. However, we are not so sure if computer hardware can keep pace with AI technologies since deep neural networks and big data processing requires great computational powers. Although Moore’s law predicts that the number of transistors in an integrated circuit doubles approximately two years, the semiconductor fabrication technique is about to reach its plateau. The quantum tunneling effect at nanoscale makes it physically impossible for engineers to shrink the size of transistors. Meanwhile, the cycles per instruction (CPI), clock speed, power consumption, pipelining and cache technologies are highly optimized in modern CPUs. These bottlenecks make it difficult to improve CPU performance and to design hardware that meets the computational requirements of AI algorithms.       It is possible to argued that, most AI practitioners are utilizing new parallel processors such as Inter Phi coprocessor or GPU for computing. However, these processors are still based on conventional computer architectures which requires I/O, memory access, etc. For example, Von Neumann architecture. Such computer architectures not only fundamentally differ from human’s brain, but poses issues in the implementation of machine learning algorithms, regardless of their computational performance. According to Steinkraus, Buck & Simard (2005), when using GPU to perform deep neural network algorithms, the CPU has to communicate with GPU via the Accelerated Graphics Port (AGP) Bus, which is limited to a bandwidth of 1 GB/s. Due to the slow data transfer rate, Steinkraus and his team has to do data preprocessing first on CPU in order to increase the transfer speed. In addition, Raina, Madhavan & Ng (2009) mentions that when using GPU for machine learning algorithms, the data locality matters. A good locality means there is a higher chance that data can be transferred with higher throughput. This also implies the bus bandwidth is a great concern in algorithm implementation, and this concern is inevitable when dealing with conventional computer architectures. Neuromorphic hardware seems like a plausible solution to power up the AI technology, but as the technical report mentions, neuromorphic computers have not yet demonstrated their powers.       In conclusion, I challenge the over-optimistic prediction of future AI proposed by this technical report since the report does not elaborate on the development of computer hardware and does not give convincing arguments that the hardware performance could meet the computational requirement of future AI. In fact, the lag between computer hardware and algorithm is prevalent in AI’s development. The idea of important machine learning models and algorithms such as neural network and backpropagation were created in the 70s and 80s, but they were not practical until the invention of fast computer hardware. It would be reasonable to expect such performance lag in the near future.       Reference:
Steinkraus, Dave, I. Buck, and P. Y. Simard. "Using GPUs for machine learning algorithms." Document Analysis and Recognition, 2005. Proceedings. Eighth International Conference on. IEEE, 2005.Raina, Rajat, Anand Madhavan, and Andrew Y. Ng. "Large-scale deep unsupervised learning using graphics processors." Proceedings of the 26th annual international conference on machine learning. ACM, 2009.                                          