Artificial Intelligence is rapidly changing our world for the better, augmenting the way we live, and making advances in nearly every field, but that does not necessarily mean it is perfect. 
When it comes to morals and ethics, putting our faith in machines is something that is still being widely debated with no guarantee of it coming to an end, or showing any sign of a winner. While this debate is acknowledged in the paper, its consequence is not discussed in detail. This dispute itself could hinder Artificial Intelligence development in general, hurting a lot of the current industries the technology is already playing a part in.  
Out of all the domains, transportation and healthcare is where the above discourse’s effect is widely observed. Self driving cars while gaining a lot of popularity among technology enthusiasts have been bashed by others mainly over the question, “In the case of an unavoidable accident, what is the car supposed to do ?” Should it minimize the loss of life or save the occupant? Now this is not a black or white situation but lets choose each answer and look at the consequences that arise from each position. In the case it chooses to minimize the death toll, most if not all would not want to buy a self driving car because everyone values their own life dearly. This could lead to less sales, leading to low profits, which ultimately would result in the downfall of the industry. Looking at the other scenario where the car’s foremost responsibility is the safety of the occupants. Now even if the number of deaths could be reduced the car would still take the route that guaranteed it’s owner’s well being. This will definitely bring about uproar in the public, which could result in research in such areas losing support financially and politically. This looks like a lose – lose situation for the automobile industry. Currently, a research done by the Toulouse School of Economics shows that the general public believes that the car should aim to minimize the number of deaths. How this plays out is just a matter of time. 
Now in the case the Artificial Intelligence does make a mistake, who is to blame? The owners of the company behind the product? Software engineers that worked on the project? Those in charge of testing, or the researcher whose work, on which the algorithm was based and this hierarchy can be stretched pretty far back. This is another problem that could potentially slow the progress in the field of Artificial Intelligence as a whole. Another argument the paper makes is that, once equipped with the right hardware Artificial Intelligence will be able to thrive even more. One thing that is not taken into account to, is that no matter how advanced the machine is physically from a secure point of view there is always scope for vulnerabilities. This pattern has been constantly repeating over decades. Hackers exploit loopholes, security analysts find these loopholes and close them and the whole process repeats again. If Artificial Intelligence gets deeply ingrained within our life even small cases of hacking can cause big problems. 
In conclusion, Artificial Intelligence is boon that can become a bane if the right measures are not taken. 

