2016’s edition of Stanford’s One Hundred Year Study on Artificial Intelligence (AI) highlights the field of Artificial Intelligence as a whole and evaluates its prospects for the next thirty years. Throughout the paper, the rapid advancements of telecommunication and the internet were mentioned as catalysts for AI’s rapid improvement over the past decades. Only a decade ago, natural language processing and conversational inference were only vague ideas in the minds of computer scientists. Now, simply speaking, “Hey Siri”, “Ok, Google”, or “Alexa…” prompt responses from all hosts of computing devices; most of which fit in our pockets. The rapid advancement of this, and many other types of AI technology is exciting and just wets the appetites of AI researchers and consumers. This breakneck speed of AI’s advancement however, should certainly be met with some degree of concern. In Stanford’s One Hundred Year Study of Artificial Intelligence, the researchers recommend removing perceived and actual impediments to research surrounding Artificial Intelligence. Decreased regulation could certainly spur growth in AI, and more advanced AI systems implemented in ways that benefit society would proffer many positive effects. Human nature, however, carries with it inherit biases, and self-interests. Without proper attention during development, many of these more advanced AI systems could fall victim to misuse and corruption. 
	
The paper does a good job of illustrating the many positive impacts that AI could lend towards society as a whole. However, it often only qualifies the many positives with offhanded remarks on it being up to developer implementation. To paraphrase; the world could have refined robot surgeons, and drone crime prevention surveillance, which could maybe have negatives if developers do something wrong. This qualification is largely understated. The role a developer plays in the creation and molding of computing platforms is enormous. Coupled with a developer being in charge of leading how an AI system learns and interprets the world, and room for human bias to enter increases exponentially. But, as the paper states, given proper attention, this could be avoided. The question that should be raised is that if regulation and oversight were not in the way of AI development, what corners would be cut in the name of progress? Regulation adds barriers that push researchers and developers to refine their systems to near perfection. Without this mediating factor, more cracks would form, and crucial safety checks could be missed. Wide-spread education surrounding Artificial Intelligence should spur incremental improvements, that gradually push the industry forward. The alternative is a system where human bias and self-interest could creep in and corrupt efforts to solve problems it attempts to address. 

Given safe advancement of Artificial Intelligence, there is little need for public concern. Any concern should lie particularly, in proper advancement of pivotal technologies like autonomous driving systems, and medicine. These two in particular highlight the need for safe, responsible development as they involve life and death decisions being made not by a human, but by AI. Instilling proper safety measures are critical to help guide AI in making correct decisions. However, at the end of the day, humans should still have ultimate control over the systems and the functions they provide. There are ultimately some problems AI cannot address with absolute certainty, but if AI is developed incrementally, thus eliminating corruption and self-interest, AI can make safer decisions, therefore contributing to overall prosperity in society. 
	

