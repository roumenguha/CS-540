Analysis of Stanford’s 100-Year Study on Artificial Intelligence

	The field of artificial intelligence has countless applications across the world, yet the article seems to give a very lenient definition to what A.I. actually is. By arguing that calculators are on the spectrum of artificially intelligent, the study allows its applications of the field to be even broader. For example, applications of AI in the public safety domain, stand out to me as stretched. Additionally, predictions of advancements in transportation, come off as overly hopeful and ambitious.  In this paper, I challenge the study by asking, “To what extent are the authors trying to ‘sell’ A.I. through the use of bold claims, unsupported evidence, and broad definitions?” I criticize the authors for becoming subjective in a study that should be entirely objective.
	The first domain that the study analyzes is transportation. Here, I find some of the study’s claim about the future to be overzealous. First, they cite an article stating that self-driving cars will be “widely adopted” (Self Driving Vehicles) by 2020, offering no explanation or analysis of this statement. Four months away from 2018, the world seems like it has a long ways to go before this wide adoption. Additionally, the study says that, “in the typical North American city in 2030, changes won’t be limited to cars and trucks, but are likely to include flying vehicles and personal robots” (Transportation). While I fully agree that all of these things may be present in the future, I also believe we are ways away from universal fully autonomous trucks and cars, and decades from “flying vehicles” and actually effective “personal robots”. This statement is sensationalized, and strikes me as an effort to appeal to people’s excitement of new technology. While it may very well prove to be true (well see in 2030), the study provides no hard evidence or statistics behind it and seems to just hope that it will come to pass.
	The study’s applications of artificial intelligence to the public safety and security domain also appear overextended. The two paragraphs that stood out to me were those discussing video surveillance and predictive policing. With video surveillance, to what extent is artificial intelligence actually applicable? The only example given in the entire paragraph was detecting police malpractice. While this is great, the rest of the paragraph simply discusses using drones and video to solve crime. This technique has been around, independent of artificially intelligent computers, and the study uses its broad definition of the field to add to its applications. In its paragraph on predictive policing, the study states that, “well-deployed AI prediction tools have the potential to actually remove or reduce human bias, rather than reinforcing it…” (Public Safety and Security). Again, there was no evidence to support this claim and it seems to me that predicting who is going to commit a crime and where it is going to happen will lead to more innocent convictions, not less, a problem that is very relevant today. Additionally, this “predictive” technique is simply the same as “looking at statistics” and again the broad definition of AI comes into play.
	Overall, the article makes many great points on the potential uses of AI and its progress. However, through hopeful and unsupported claims and a broad definition of AI, the authors tailor the study to reflect their hopes for artificial intelligence. Additionally, they try to “sell” the concept of AI to the general public, and while it is not inherently a bad thing, they overstep the bounds of the study and very clearly take sides on something that should be objective.
