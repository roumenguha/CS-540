Challenge Statement: The One Hundred Year Study (OHYS) makes a wide variety of assessments and predictions about artificial intelligence. One repeated theme is in the potential of new AI technologies to have either positive or negative effects for the majority of people, particularly vulnerable people, depending on how they are implemented and regulated. This is certainly true, but the study arguably makes two mistakes: it is too optimistic about the fairness with which AI will be applied and to whom its benefits will accrue, and the solutions to such problems of fairness are likely to require fundamental political change, rather than technical or regulatory adjustments within current political structures.

When sweeping new technologies such as AI are introduced, they tend to reinforce existing inequalities in power and wealth, rather than level them. This is because the current holders of power in society  such as large corporations, police, or regulatory agencies  control the creation and implementation of the technologies, access to the technologies, and the terms in which the technologies are applied.

One such example is in news media. It was widely predicted that social media would reduce peoples reliance on a few respected media corporations and democratize public discourse. Facebooks rise has seen this effect happen  but at the cost that now Facebook itself controls a huge and increasing fraction of peoples news consumption and sharing, in a completely opaque way. This is mostly due to social media network effects, but mirrors a broader trend in the field of companies who have access to sophisticated machine learning techniques. Because they are trained on huge datasets, only the biggest few companies (such as Facebook, Google, Wal-Mart, and Amazon) can use these techniques, leading to natural monopolies and, more broadly, the increasing stratification of wealth in society.

Another example is in the use of machine learning algorithms to determine criminal sentencing or to predict crime. The algorithms and the data they are trained on are all controlled by people who tend to be favored by the criminal justice system in the first place  whiter, wealthier, and better educated. On top of that, the use of these programs is itself controlled by the notoriously racist criminal justice system. But because all of these layers of discrimination are abstracted behind a seemingly impartial computer program, they are obscured and therefore protected. There have already been documented cases of racist programs used by our criminal justice system, and there will likely be many more.

The study references such issues in a few places, such as on page 43. It points to regulatory solutions to resolve these problems of unequal access to and treatment by AI. This is flawed because it views AI technology itself as a potential root cause of increased discrimination and related problems or solution to them. In reality, AI is a tool like any other, which only amplifies the power of groups with access to it, regulated or not. To prevent AI from being used to expand our police state, further criminalize poverty, or reinforce racial disparities, we must overturn the power relations that originally led to those problems. This involves increasing the political power of minorities and poor people, especially as they come into conflict with the state and the largest and most predatory corporations. This would require the dramatic expansion of democratic power, not just into government, but into the functioning of private corporations whose behavior affects everyone. Until then, it is likely that we will see only a continuation of current trends.

