	Though this was a very expansive study, I feel that the panel avoids one of the biggest oppositions to AI: human stubbornness and utter refusal to adapt.  While they note that AI will need to gain the “trust” of its users, one of the biggest things they ignore is that many people (regardless of the level of trust) will refuse to use AI.  A few examples may include: those who enjoy and prefer maintaining full control over a vehicle, those who prefer surgical operations from a licensed human doctor, those who want their grandparent to be supervised by a human capable of adapting to any situation.  What will happen to an auto-enthusiast when a city does away with its parking spots due to autonomous vehicles?  Will they then no longer be able to take their beloved vehicle out for anything but joy rides with home being the only destination?  Rather than jobs like home health aides becoming obsolete due to robots, I imagine that the few humans who remain in the job sector will make more money than before, as it will become an expensive privilege to be able to afford a human helper.  I for one, no matter how many surgeries a machine has successfully completed, would pay whatever the upcharge may be to have a human surgeon perform my surgery.  I feel that this study completely overlooks most people’s preference for human interaction, at least in life or death situations.	Apart from pure refusal to adapt, another major disagreement I have with the study is the prediction of flying cars.  While this has always been seen as a staple of the future, the logistics are far too absurd.  When you take into account how many regulations there are on a simple lightweight drone in an airspace, the concept of a 2-ton vehicle flying overhead becomes ludicrous.  It is my belief that an underground tunnel system would be implemented far before any flying cars.	When concerning public statistics, I find that there is a major oversight concerning the concept of outliers.  While using predictive software in situations such as granting parole, the ability for humans to completely change their behavior on a dime cannot be ignored, no matter how strong the evidence is against it.  No amount of statistics or intelligent projections can predict human spontaneity.  Grouping people into subgroups based on historical evidence will only reinforce that individual’s probability of remaining there.	The last and most important oversight of this article was avoiding the influence of military advancements.  The article stated that: “military applications were deemed to be outside the scope of this initial report”.  The capitol and labor allocated towards researching AI in the domain of national defense could outweigh the private sector tenfold.  For example, although the study panel doesn’t expect drones capable of swimming by 2030, if a national security concern required drones that swim, the military resources could see these machines finished within the year.  While I understand that military research is kept secret and can be unpredictable, the massive steps forward it could potentially provide should not go without consideration.