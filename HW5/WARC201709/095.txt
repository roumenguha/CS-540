The use of AI in education will not replace high level educators. The strengths cited by the study do not lend themselves well to human education. Furthermore, the current learning algorithms do not accurately emulate the process a human goes through to learn, and the two ‘neural networks’ are not comparable.
The article states that AI mimics good human tutors by “providing hints when a student gets stuck on a math problem”. To avoid an ungracious interpretation of this, it is also implied that this AI ‘hint machine’ should be partnered with a tutor for maximum effectiveness. 
This is an ineffective use of AI, and will make a minor difference on the learning rate of the student. What makes a tutor good is not his knowledge or even ability to teach new skills. Rather, what makes a tutor effective is his ability to figure out what a student can confidently do, and how to increase the students’ confidence in other abilities. This dynamic is fragile—the tutor must not only know algebra to teach substitution, but he must also have a strong intuition of the students’ perception of substitution. Without the combination of these two, the tutor will not effectively address the issue. For the tutor to effectively teach substitution, he will have to figure out how the student is best able to understand the concept, and move forward in this direction. For example, if the student has a very strong grasp of the orders of operations and commutative properties, then the educational approach must necessarily differ from the approach taken on a student who does not understand these concepts.
Furthermore, there is a certain intuition about the human learning function that humans possess that cannot be mirrored in machines. A tutor might realize that the student forgets to carry numbers in addition, as demonstrated by the student’s work. An error as elementary as this may be caught by the machine, but there are other structural issues that only a human would pick up on. For example, if a student solves systems of equations with a matrix, then the errors the human might make could not possibly be a substitution problem. Or if the student uses addition and multiplication to reduce terms, then the tutor might realize that the student does not properly distribute the multiplication properly. Or from the tutor’s past experiences, he might already have an idea as to where the student is likely to run into troubles, and he can proactively plan for that. 
In these ways, an AI cannot reasonably emulate a human, and as a result education must be primarily human driven for the time being. 
