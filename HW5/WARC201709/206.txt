	In " Artificial Intelligence and Life in 2030", the one Hundred year Study on Artificial Intelligence, claims of widespread adoption of safety critical automation seems to be focused more on the technologies available and passingly mentions other influences as a potential roadblocks. Specifically, self-driving cars at its most optimistic approximation of 3 years until widespread adoption seems to not take in general public feedback into the equation. Subjects such as safety, ethics, and law will deeply impact and challenge the overall adoption of presented in the study and will delay said adoption until all intricacies are worked out.
	Safety as an aspect of self-driving cars will rule all implementation of the cars ability. The self-driving car will have to react to its environment in a predictable and safe manner. Widespread adoption of self-driving cars will bring safety tests to a new level as the sheer volume of autonomous cars will only drive self-driving car accidents up. A new definition of safe will have to be defined for these vehicles.
	Defining a safe self-driving car strains ethics regarding its own safety. Autonomous cars will assumedly drive down driving related accidents, otherwise mass adoption would be out of the question. How safe does a self-driving car have to be? A metric would have to be recorded as to measure the vehicles safety. A metric that could be reasonably described is its “percent safety”, a percentage based on how safe the vehicle would as compared to a human driver, with 100% being the vehicle makes all mistakes a human driver could make (including deadly) and 0% being the vehicle never makes mistakes. In a perfect world, all autonomous cars would have a “percent safety” of 0%, but the world is not perfect. At what “percent safety” deems the vehicle as safe enough? Who is qualified to determine this value? This ends up being a real world implementation of the “Trolley problem”. Morally speaking, a lower “percent safety” will always be better. Participation in setting a reasonable “percent safety” constitutes assumption of responsibility of the lives risked. Furthermore, setting any “percent safety” at all violates the incommensurability of human life. The only acceptable “percent safety” of 0% is impossible to achieve, especially since the first death related to self-driving cars has already occurred. Who assumes responsibility of lives risked? Would it be the at the hands of the individual who set the required “percent safety” or the agency who developed the self-driving car? These questions would have to be answered not only by the public, but with new social standards backed by law making.
	All ethical issues relating to self-driving cars would have to imbue itself into law. Development of said laws will take time, as mass adoption of AI would have to occur before the solution to the proposed ethical problems could commence. Not only would this set the standard for all safety critical automation done by AI, but also must take into consideration other industries, as self-driving cars are not the only safety critical automation available. This whole process could take an indefinite time, as the moral problems described could easily implant itself in our current socio-political climate of today.
