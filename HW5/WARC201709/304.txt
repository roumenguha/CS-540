One Hundred Year Study on Artificial Intelligence (AI100) is an article introducing what Artificial intelligence is and predicting what people’s life will be in one hundred years. It mainly describes eight areas that would be impacted by the development of AI. Although the analysis and the prediction have their own merits, they contain some flaws. 

Before reaching the eight areas, the article mentions that “the Study Panel found no cause for concern that AI is an imminent threat to humankind.” It seems that authors of the article agree with the point of view. Nonetheless, the truth is likely to be contrary to their opinion. While browsing webpages or finding something interesting online, people do not usually expect any inappropriate messages. However, it happens. 

Tay was an artificial intelligence chat robot that was released by Microsoft via Twitter. It was supposed to be a great experiment to test how AI study and learn through people besides programmers. Surprisingly and unfortunately, Tay was shut down only 16 hours after its release. Tay began posting racial discrimination messages and other extremely inappropriate messages after its launch. Microsoft had to shut the service down when it found that Tay was not behaving in ways that Microsoft expected. This is an actual example that AI can be a threat to humankind. Tay learned so many unexpected knowledges within hours through internet/people. Yet it did not understand those messages and began posting what it had learned. Since people hiding behind screens do not get punished, many of them started teaching Tay inappropriate things unscrupulously. In the future, AI might still learn things through the same way. People can hide behind screens and do whatever they want. Assuming we have police AI robots in one hundred years, if people can teach those robots or simply change the AI’s knowledge of definition of crime in the same way, it would be a great threat to humankind. 

After reaching the eight areas, many counter arguments can be made to certain issues. Some areas have more issues than others. Among these areas, self-driving is a big problem. The article suggests a future that self-driving would be well accepted and gives some tips for the future. However, discussions of self-driving are vague in some aspects. For instance, the authors never discuss how self-driving works.  Do all AI self-driving vehicles learn driving via the same computation system? Do they share the same internet service while on the road? What happens if there is an emergency? Under the circumstance that some people have urgent events while some people do not really care how fast the car drive, do self-driving AI knows what to do? When there is an emergency, how fast and accurate can AI react? It is commonly known that human can react to emergencies pretty fast because unconscious mind of human always tries to keep human alive and avoid dangers. While facing emergencies, computers need to “observes” the event, transfer the event into data, and run calculations. This process may take a while depends on the circumstance. The judgement is an issue, too. During emergency, what judgement an AI would make? Instant breaking may have killed the driver. On the other hand, keeping driving may have killed two other people. Would it choose to save the two people and kill the innocent driver? 
There are many more problems and flaws in the article. The authors’ positive attitude toward AI’s future should be encouraged. However, every aspect of AI should be examined and discussed. A possible bright future with AI does not mean that there is no issues or risks. 
