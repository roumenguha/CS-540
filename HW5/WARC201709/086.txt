    Is artificial intelligence a misnomer? Can we ever truly consider a machine to be intelligent? A line must be drawn; there is a difference between knowing and being able to truly utilize what one knows. As Merriam Webster dictionary defines it, intelligence is “the ability to acquire and apply knowledge and skills.” Stanford’s 100 year report predicts that as companies begin to operate with greater amounts of information at their disposal through concepts such as Internet of Things, their technology will consequently become increasingly receptive to human needs. But is this real intelligence?
    In this age of information, machines process more and more data every day – but how much of it actually gets meaningfully digested? Without comprehension, can the storage and algorithmic retrieval of data truly be counted as intelligence? On page 13 of Stanford’s 100 year study it is stated that “as a rule of thumb… any activity computers are able to perform and people once performed should be counted as an instance of intelligence.” I challenge this. It’s more often the case that jobs that machines can readily take over are seen as overly-simplistic. Prior to automation, packaging cans by hand and stapling papers together were tasks routinely carried out by humans, though one would be hard-pressed to describe these worker machines as “intelligent.”
    Even raising the bar to a task that many humans see as epitomizing intelligence – playing chess – we find that the programmers responsible for the machine capable of beating the human world champion don’t deign to call it “intelligent” (page 13). Even in the glow of its victory, it was derided as being a simple “collection of ‘brute force’ methods.”
    So, what is intelligence then? One of the founding researchers of artificial intelligence, Nils John Nilsson, on page 12 defines intelligence as “that quality that enables an entity to function appropriately and with foresight in its environment.” From my own belief, this echoes the key element that separate humans from other animals: formulation of abstract thought. While they lack a finely tuned sense self-preservation (and for this we should be grateful), both qualities are the products of the billions of years of evolution that have allowed humans to attain their immense versatility. On the other hand, outside of a prescribed set of conditions, machines do not thrive. They fail to consistently adapt to any challenge they are confronted with.
    So, can anything that didn't arise from countless millennia of trial-and-error be considered worthy of designation "intelligent"? That’s a fairly steep demand. More optimistically, could genetic algorithms be considered the first semblance of true "intelligence" in a machine? Through so many generations of selection, they are able to grow effective “neurons” to aid in decision making. The artificial “intelligence” that this results in would be comparable to a rudimentary living organism, reacting to only the most basic stimuli in its environment. Are the digital signals of a circuit board so different from the electrochemical signals of the brain? For now, they are. But the gap between artificial intelligence and true intelligence grows smaller by the year.


