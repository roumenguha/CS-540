CS 540-2: Introduction to Artificial Intelligence
Homework Assignment # 1
9/13/17

Write a short essay to challenge one or more aspects of the Stanford One Hundred Year Study on Artificial Intelligence. Requirements with point distribution:
10 Your essay should be between 500 and 600 words.
10 The essay should be a single plain text file in English. No pdf, word, rtf, etc., and no attachments of audio, video, images, etc. please. Name your file hw1.txt
10 Do not include your name, your family, friends, or any private and sensitive information in the essay. Your essay will be read by others, including your fellow students.
20 Make a clear statement of your challenge.
50 General scholarly writing. Other than the above requirements, you have complete freedom in format and content.

While the Stanford “One Hundred Year Study on Artificial Intelligence” (Stone et al., 2016) addresses many potential difficulties with innovation and advancement in Artificial Intelligence (AI) as it applies to various domains, the study panel is overall optimistic about the future of AI and the value it can bring to society. This is not a worrisome perspective to take by any means. As a supporter of the advancement of AI technologies, I cannot help but to agree with almost everything the study had to say, so finding aspects to challenge proved difficult. However, I maintain that the study is perhaps too optimistic about what AI can and will do, particularly as it pertains to healthcare. 

Much appreciation can be had for the study’s attempts to expel worry about AI as a potential threat to society. Whenever the topic of AI comes up in casual conversation, the other person will often bring up the concern about computers taking over the world. Every time this comes up, I offer my opinion that we simply are not there yet. As the study mentions, AI systems have extremely specific applications and can only do as much as they are programmed to do. However, while evil, sentient computers are not an immediate threat, there is still danger in human error and oversight. This oversight is especially harmful in the healthcare domain. 

The study is careful not to make any far-reaching claims about what AI can do, but one application of AI to healthcare mentioned is its potential to help diagnose medical conditions. There are several concerns to consider here. First, there is an immediate limitation when it comes to very specific, rare diagnoses, and diagnoses where even physicians have a high rate of misdiagnosis. How will the system decide which diagnosis to go with when probabilities of it being one as opposed to another diagnosis are similar? A solution might be integrating AI with human interaction, which the study emphasizes the importance of (and acknowledges as a challenge). This is a possibility, but what if the human interacting with the technology is prone to error? This can lead to major consequences as the act of making a medical diagnosis is incredibly nuanced. In the best case, the technology makes an accurate diagnosis, but in a worse case, the technology might over-diagnose. One is reminded of searches on WebMD, where anything can be cancer. In the worst case, the technology might under-diagnose, where the patient has a far worse condition than the technology indicates. Second, physician burnout is a pervasive problem and the cognitive load for a typical clinician is already quite high. It will be difficult, unrealistic even, to expect clinicians to be as involved as they will need to be to be able to help advance AI in the healthcare domain to the degree that the study suggests is possible. Third, there is the worry of humans becoming too dependent on technology. The study visualizes the clinician as a type of facilitator, but there is a human tendency to rely heavily on tools once made available, such as the example of students becoming reliant on their calculators. Taking this into consideration, there is great potential for AI in the healthcare domain to lead clinicians astray, which can prove drastic.

The stakes are high for healthcare, and while the fear of an evil AI is perhaps unfounded, mistakes made during conception of the technology can have major consequences. If we're not careful, we can create something we did not mean to create.
