While I don’t think enough can be said about the importance AI will play in the future of humanity, I think the “One Hundred Year Study on Artificial Intelligence” downplays the potential of bad actors wielding malicious and powerful AI. It is one thing to discuss the impact AI will have in countries with well-balanced governments. However, an entirely different discussion arises when countries with supreme rulers are considered. A poor intentioned dictator might leverage AI to spy on every citizen in his/her country. AI makes this increasingly easy. In the past, vast resources (people, money, and time) had to be invested to spy on the citizens of a country. The increasing power/scalability of AI makes it orders of magnitude easier to know much about each citizen. This is already happening in countries like Iran where “deep packet inspection” is being used to intercept and record as much personal information as possible. The president of Zimbabwe hasn’t lost an election since the government mandated internet service providers save information about users in a national database. Abuses such as these will be used by oppressive governments, or simply paranoid leaders who want to spy on political opponents.

The solution to an abuse of AI is not easy or clear cut. One solution might use AI against oppressive dictators (and potential future ones). I think the paper needs to place more emphasis on using AI to develop ultra-secure methods for humans to communicate. If researches become aware of present and future abuses, they will be more likely to take actions that could save thousands of lives.  It will be hard to push the conversation forwards, however, since governments tend to be against advances in privacy and security measures. Such measures will not be popular with government officials, but citizens in countries with controlling regimes need an easy, mainstream way to communicate without any government or company intruding.

The paper agrees with the assertion that it is never too early to start discussing important ramifications for AI and I think this is a vital discussion to have. Whatever the solution might be, considering future abuses of AI has to be an important part of the conversation while technologies are moving forwards at such a rapid pace. With so many publicly available methods, it might be possible for a group of hackers (with enough processing power) to cause great damage. What if the group creates an AI that finds vulnerabilities in software, exploits the vulnerabilities, then uses them to wreak havoc? Maybe the malicious group uses AI to find people on social media (posing as someone the victim would likely friend), then uses this insider access to steal the identity of the victim. All of this could happen without any interaction from the hacker. 

The potential of AI is huge and I welcome the advances with open arms. However, I think more of an emphasis needs to be placed on furthering security/privacy. The paper properly responds to those that think AI will become sentient and take over the world, but I believe it does not correctly address the very real threat of humans abusing specialized AI to take away the rights of citizens across the globe. 

