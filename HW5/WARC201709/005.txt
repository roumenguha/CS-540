One of the aspects of Stanford’s One Hundred Year Study of Artificial Intelligence that I would like to challenge is the issue of how to handle bias that can be potentially introduced by AI.  They mention that one particular challenge of creating AI that predicts things based on people’s behavior is to make it independent of things such race, gender, or sexual orientation, but are optimistic that with careful design and planning this can be overcome to allow the AI to take over the decision-making process.  I believe that they have not properly acknowledged the possibility of certain coincidences in AI decisions that might cause a public perception of biased AI anyways even when the proper steps are taken to address the issue during its design.  If a certain demographic of people in society happen known for having commonly having some kind of characteristic but do not necessarily exclusively hold that characteristic, an AI making a decision based on that characteristic could appear biased for or against that group of people even though it was not designed to specifically target that demographic.
The study references the fact that companies are already utilizing machine-learning applications to predict credit-risk.  This can greatly affect whether people can get loans and other forms of credit, and as such needs to be as unbiased as possible.  The issue of perceived bias could come into play if there coincidentally happened to be a demographic in society that just happened to have a lot of people with bad credit scores and history.  Even if the AI was designed to only consider the numbers (credit scores) when making decisions about loaning money and ignore the demographic types of the people it is evaluating, the overlap could cause that AI application to appear biased against that demographic group, even though it is not technically biased against that demographic.  This could then be used to sow mistrust among the general population against AI in general, which would be counterproductive when considering the AI study’s additional goal of ensuring that AI is used in a manner that does not cause the general populace to fear and distrust it.
I believe that these sorts of coincidences will require that a clearer definition of what constitutes bias in the context of decision-making AI in addition to designing AI to be as unbiased as possible.  Coincidences like these can easily be used to make AI appear to be biased even when they are designed in a way to ignore such biases.  It will be up to humans to decide which of the perceived biases are coincidences and which are actually cases of AI being biased against certain groups, and take corrective action when actual cases of bias are found.  The people in charge of creating these AI applications will also be responsible for educating the general population about this issue and ensuring transparency when the inevitable controversies about biased AI surface.  This will ensure that these sorts of coincidences are not used to turn people against the use AI in decision-making applications, which when done correctly can provide a great benefit to society.