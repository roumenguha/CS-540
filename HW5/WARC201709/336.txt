	The Stanford One Hundred Year Study prioritizes topics including the advancement of research and economic concerns over the health and well being of people in the discussion of societal affairs that must be addressed before artificial intelligence advances and integrates further into society. While these two topics must be discussed and debated as AI progresses, it should be obvious that the effects of AI on the health and lifespan of humans should be the number one thing to be carefully deliberated, as human lives are a fragile and delicate matter, both literally and figuratively. 
	The study discusses the impacts of AI in the healthcare analytics realm. It states “If regulators (principally the FDA) recognize that effective post-marketing reporting is a dependable hedge against some safety risks, faster initial approval of new treatments and interventions may become possible” (27), a statement that is problematic. The study panel seems to imply that regulators should consider the benefits of predictive analytics research over human health and safety. While this type of research is certainly beneficial, no research is worth a loss in the quality of life. Human lives are not something to be played with so carelessly in an effort to advance research. 
	The study talks about the water crisis in Flint, Michigan later in the article (35) and points out that predictive models are currently being put in place to assist children at risk of lead poisoning. The study panel’s concern for human safety with the water crisis is directly contradicting their views on the regulation of potentially harmful software. To remain in alignment with the their views on Flint, they should want regulation of the AI software to be rigorous in order to prevent another crisis of human health and safety from occurring. 
	Their laissez-faire attitude on human safety continues with their views on the value of emerging healthcare imaging software. The study states, “Even with state-of-the-art technologies, a radiologist will still likely have to look at the images, so the value proposition is not yet compelling” (27). The study panel believes that going through two steps, both important in the accurate diagnoses of patients, is an economical waste of time, and thereby, lacking value. 
	This statement is puzzling in two ways. First, the authors are prioritizing the economic value of a technology over the human verification that many AI technologies simply require in order to uphold medical safety standards. Second, they iterate several times throughout the article that AI technology is used most advantageously in complement with human skills. Expressing that the work of a radiologist in pair with AI software is not valuable is hypocritical to their opinions in the rest of the study.
	I agree with the study panel in their worry that artificial intelligence research will create privacy issues, and may even create issues of racial bias and micro aggressions. Nonetheless, it is perplexing to me why the authors care a great deal about the social issues AI technology may perpetuate but not the biological issues it may cause if we prioritize research and economic gain over health and safety. There are some risks not worth taking. 

Bibliography: 2015 Study Panel. “Artificial Intelligence and Life in 2030.” Stanford's One Hundred Year Study of Artificial Intelligence, Sept. 2016, pp. 1–52.