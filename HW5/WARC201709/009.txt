What everyday life will look like in the coming years is somewhat murky, due to the prospect of artificial intelligence. Artificial intelligence is defined as anything that completes a task that normally would need a human brain. This means that AI is not just the stereotypical Siri or an Amazon Echo, but it is also things such as Uber or a button you hit to sort emails. One area where AI could really change day to day life is in the realm of transportation, and more specifically cars. Self-driving cars have been dreamed of since cars were first created, and recently big companies have been developing more and more refined prototypes. One report in the Stanford One Hundred Year Study on Artificial Intelligence even predicts self-driving cars to be widely adopted by 2020. It does not seem likely that within the next three years self-driving cars will become normal in day to day use. This is because of the current state of the technology as well as practicality and legal concerns. 
One of the main concerns of automated cars is that they are not as adaptable as a human. An example of this would be if a car is in a parking lot trying to get out of a sporting event or a concert. Getting out of a crowded parking lot takes a lot of thinking from a person, such as reading signs with instructions to get out of the parking lot and watching out for people walking around. How would a car read signs, and if it could how would it be able to figure out how to execute the instructions on the sign? What would a car do if a traffic signal is out or there is somebody directing traffic? These are all questions that would need to be answered before self-driving cars would be widely adopted and it does not seem as if they will be answered in the next three years.
A logistical reason that self-driving cars will not be used very often within the next three years is that it is still unknown who would be responsible in the event of a crash. If two automated cars got into an accident which driver would be responsible for the damages? It would not make much sense for a driver to be responsible for a crash if the cars were being operated by computers programmed by the self-driving car company. Which would mean that self-driving cars would have to be near perfect or rules created that would say who is responsible for a crash, otherwise every crash would just result in the creators of the car losing money. 
Lastly, the biggest strength of automated cars would be that they can communicate with each other. Each car would know what the other is about to do and there would never be a crash. However, while this is possible in the future, not everyone will own a self-driving car in the next three years, or even in the next ten. If there are still human drivers out there the system will not be perfect and there will still be plenty of crashes because a computer cannot predict what another driver is about to do. Not everyone will be able to afford a self-driving car and not everyone will be willing to give up driving because they like to drive.
While the prospect of all fully automated cars can be seen on the horizon it will not occur within the next three years, or even in the next ten because of technological and logistical obstacles it has yet to overcome.
