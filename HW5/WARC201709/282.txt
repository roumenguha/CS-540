Artificial intelligence, as pointed out in the study, has a  bad reputation in the public's mind. Much of what the public knows about AI comes from movies and books, and almost all of these plots revolve around  an intelligence whose goal is to harm humanity. The panel is right in saying that these are highly improbable situations and they rightly address these concerns by suggesting that those in the government be aware of what AI is and how it can impact the future.  However, I believe they went a little overboard with their recommendations. On page ten of the study they recommend that all levels of government acquire technical expertise and talent in AI.  I do not believe this is necessary because it will distract from innovation, detract from agencies that truly need the expertise, and for non critical areas it will become obsolete.
         Having the government acquire talent to help develop regulations distracts from innovation. First, we must recognize that AI has just recently made its conversion from academia to being economically viable. Couple that with the fact that  it’s a esoteric field with a high barrier to entry, it is unsurprising that universities only produce a handful of graduates who have studied this field well enough to make improvements in it. One can view this as a shortage of labor; companies need these graduates to help them innovate and refine their products. But,if these graduates go to work for the government then they do not “move the ball forward” and thus overall innovation is slowed. 
        Some government agencies, however, need AI expertise. Examples of these agencies would be ones involved in economic and market regulations and well as security. Applying AI regulations to these areas makes sense and can have a positive impact for everyone. However, there agencies must have enough employees  that are well versed in AI in order to create these regulations. As pointed out up above, there are a limited number of people who actually understand this stuff and its potential. It seems like a waste to me to hire someone who has  achieved  a high level of understanding  and expertise to work for  agencies who are not dealing with disruption. Also, I don’t believe that all  levels of government need AI expertise.  It does not make sense to me to hire an AI expert for local lawmakers. AI, much like the internet, will eventually operate on an international level. Any problems that would arise would likely affect hundreds of thousands of people, if not millions of people. Therefore it makes sense to have AI experts working for governmental bodies that have jurisdiction on a federal, national, and at the least, state level.
         I also think it would be a wise idea to wait some of the this new technology out. As pointed out in the study, after the public at large becomes familiar with AI algorithms in their daily lives, they aren’t considered AI any more. For example, email spam filters run on AI algorithms. they look for strange email addresses and keywords that indicate it’s a spam message. This is more or less equivalent to letting your email provider sift through your messages. Most people don’t have any concerns about this. It may be the same way for new developments in the upcoming years. Front loading regulations onto new technologies hampers development and may turn out to be obsolete in the near future.  This might not seem so bad, but creating these regulations takes time and money that could be put to a better use somewhere else.
        Overall, while I appreciate that this panel takes the concerns of the public seriously, My concluding thought is that what they recommended is not viable nor is it the best course of action.